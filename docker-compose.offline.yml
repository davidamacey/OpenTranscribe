version: '3.8'

# OpenTranscribe Offline Deployment Configuration
# This compose file is optimized for air-gapped systems with no internet access
# All images are expected to be pre-loaded using 'docker load'

services:
  postgres:
    image: postgres:17.5-alpine
    pull_policy: never
    restart: always
    volumes:
      - postgres_data:/var/lib/postgresql/data/
      - ./database/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-opentranscribe}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    pull_policy: never
    restart: always
    volumes:
      - minio_data:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "${MINIO_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 10s
      retries: 5

  redis:
    image: redis:8.2.2-alpine3.22
    pull_policy: never
    restart: always
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  opensearch:
    image: opensearchproject/opensearch:2.5.0
    pull_policy: never
    restart: always
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - DISABLE_SECURITY_PLUGIN=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    ports:
      - "${OPENSEARCH_PORT:-9200}:9200"
      - "${OPENSEARCH_ADMIN_PORT:-9600}:9600"
    healthcheck:
      test: ["CMD-SHELL", "curl -sS http://localhost:9200 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 20

  backend:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    restart: always
    volumes:
      # Model cache directories - must be owned by UID 1000 on host
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/torch:/home/appuser/.cache/torch
      - ${TEMP_DIR:-/opt/opentranscribe/temp}:/app/temp
    ports:
      - "${BACKEND_PORT:-8080}:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-opentranscribe}
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MEDIA_BUCKET_NAME=${MEDIA_BUCKET_NAME:-opentranscribe}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-change_this_in_production}
      - JWT_ALGORITHM=${JWT_ALGORITHM:-HS256}
      - JWT_ACCESS_TOKEN_EXPIRE_MINUTES=${JWT_ACCESS_TOKEN_EXPIRE_MINUTES:-1440}
      - MODELS_DIRECTORY=/app/models
      - MODEL_BASE_DIR=/app/models
      - TEMP_DIR=/app/temp
      - USE_GPU=${USE_GPU:-true}
      - TORCH_DEVICE=${TORCH_DEVICE:-cuda}
      - COMPUTE_TYPE=${COMPUTE_TYPE:-float16}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v2}
      - BATCH_SIZE=${BATCH_SIZE:-16}
      - DIARIZATION_MODEL=${DIARIZATION_MODEL:-pyannote/speaker-diarization-3.1}
      - MIN_SPEAKERS=${MIN_SPEAKERS:-1}
      - MAX_SPEAKERS=${MAX_SPEAKERS:-10}
      # LLM Configuration - external providers only for offline deployment
      - LLM_PROVIDER=${LLM_PROVIDER:-}
      - VLLM_BASE_URL=${VLLM_BASE_URL:-http://localhost:8012/v1}
      - VLLM_API_KEY=${VLLM_API_KEY:-}
      - VLLM_MODEL_NAME=${VLLM_MODEL_NAME:-gpt-oss-20b}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME:-gpt-4o-mini}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://localhost:11434}
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-llama2:7b-chat}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL_NAME=${ANTHROPIC_MODEL_NAME:-claude-3-haiku-20240307}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OPENROUTER_MODEL_NAME=${OPENROUTER_MODEL_NAME:-anthropic/claude-3-haiku}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL:-https://openrouter.ai/api/v1}

  celery-worker:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    restart: always
    command: celery -A app.core.celery worker --loglevel=info -Q gpu,nlp,utility,celery --concurrency=1
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              device_ids: ['${GPU_DEVICE_ID:-0}']
    volumes:
      # Model cache directories - must be owned by UID 1000 on host
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/torch:/home/appuser/.cache/torch
      - ${TEMP_DIR:-/opt/opentranscribe/temp}:/app/temp
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-opentranscribe}
      - MINIO_HOST=minio
      - MINIO_PORT=9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MEDIA_BUCKET_NAME=${MEDIA_BUCKET_NAME:-opentranscribe}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - MODELS_DIRECTORY=/app/models
      - MODEL_BASE_DIR=/app/models
      - TEMP_DIR=/app/temp
      - USE_GPU=${USE_GPU:-true}
      - TORCH_DEVICE=${TORCH_DEVICE:-cuda}
      - COMPUTE_TYPE=${COMPUTE_TYPE:-float16}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v2}
      - BATCH_SIZE=${BATCH_SIZE:-16}
      - DIARIZATION_MODEL=${DIARIZATION_MODEL:-pyannote/speaker-diarization-3.1}
      - MIN_SPEAKERS=${MIN_SPEAKERS:-1}
      - MAX_SPEAKERS=${MAX_SPEAKERS:-10}
      # LLM Configuration
      - LLM_PROVIDER=${LLM_PROVIDER:-}
      - VLLM_BASE_URL=${VLLM_BASE_URL:-http://localhost:8012/v1}
      - VLLM_API_KEY=${VLLM_API_KEY:-}
      - VLLM_MODEL_NAME=${VLLM_MODEL_NAME:-gpt-oss-20b}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME:-gpt-4o-mini}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://localhost:11434}
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME:-llama2:7b-chat}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL_NAME=${ANTHROPIC_MODEL_NAME:-claude-3-haiku-20240307}
      - ANTHROPIC_BASE_URL=${ANTHROPIC_BASE_URL:-}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OPENROUTER_MODEL_NAME=${OPENROUTER_MODEL_NAME:-anthropic/claude-3-haiku}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL:-https://openrouter.ai/api/v1}

  frontend:
    image: davidamacey/opentranscribe-frontend:latest
    pull_policy: never
    restart: always
    ports:
      - "${FRONTEND_PORT:-80}:8080"
    environment:
      - NODE_ENV=production
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  flower:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    restart: always
    command: >
      python -m celery -A app.core.celery flower
      --port=5555
      --url_prefix=flower
      --persistent=True
      --db=/app/flower.db
      --broker=redis://redis:6379/0
    ports:
      - "${FLOWER_PORT:-5555}:5555"
    depends_on:
      - redis
      - celery-worker
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
    volumes:
      # Model cache directories - must be owned by UID 1000 on host
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/torch:/home/appuser/.cache/torch
      - flower_data:/app

volumes:
  postgres_data:
  minio_data:
  redis_data:
  opensearch_data:
  flower_data:
