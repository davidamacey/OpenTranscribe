# Multi-platform Dockerfile supporting CUDA, MPS, and CPU
# Automatically selects appropriate PyTorch build based on target platform

ARG TARGETPLATFORM
ARG BUILDPLATFORM
ARG TARGETOS
ARG TARGETARCH

FROM python:3.10.12-slim-bullseye as base

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    ffmpeg \
    libsndfile1 \
    libimage-exiftool-perl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Create directories for models and temporary files
RUN mkdir -p /app/models /app/temp

# Create non-root user for security
RUN useradd --create-home --shell /bin/bash app && \
    chown -R app:app /app
USER app

# Set up environment
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Copy requirements and install base dependencies
COPY --chown=app:app requirements.txt .

# Install base Python dependencies (without PyTorch)
RUN pip install --user --no-cache-dir \
    $(grep -v "^torch" requirements.txt | grep -v "^torchaudio") && \
    pip install --user --no-cache-dir "numpy<2.0"

# Platform-specific PyTorch installation stage
FROM base as pytorch-cuda
# CUDA/Linux PyTorch
RUN pip install --user --no-cache-dir \
    torch==2.2.2+cu118 \
    torchaudio==2.2.2+cu118 \
    --index-url https://download.pytorch.org/whl/cu118

FROM base as pytorch-cpu
# CPU-only PyTorch (works for both Intel/AMD and Apple Silicon via Rosetta)
RUN pip install --user --no-cache-dir \
    torch==2.2.2+cpu \
    torchaudio==2.2.2+cpu \
    --index-url https://download.pytorch.org/whl/cpu

FROM base as pytorch-mps
# Apple Silicon PyTorch (with MPS support)
RUN pip install --user --no-cache-dir \
    torch==2.2.2 \
    torchaudio==2.2.2

# Final stage - select appropriate PyTorch build
FROM pytorch-cpu as final-cpu
FROM pytorch-cuda as final-cuda  
FROM pytorch-mps as final-mps

# Default to CPU if no specific target
FROM pytorch-cpu as final

# Auto-select based on build arguments and environment
ARG TORCH_VARIANT=auto
ENV TORCH_VARIANT=${TORCH_VARIANT}

# Copy application code
COPY --chown=app:app . .

# Set Python path to include user packages
ENV PATH="/home/app/.local/bin:$PATH" \
    PYTHONPATH="/app:$PYTHONPATH"

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# Expose port
EXPOSE 8080

# Development vs Production entry point
ARG BUILD_ENV=production
ENV BUILD_ENV=${BUILD_ENV}

# Entry point script for hardware detection and optimization
COPY --chown=app:app <<'EOF' /app/entrypoint.sh
#!/bin/bash
set -e

echo "ðŸš€ OpenTranscribe Backend Starting..."
echo "ðŸ” Detecting hardware configuration..."

# Run hardware detection
python3 -c "
from app.utils.hardware_detection import detect_hardware
import os

config = detect_hardware()
summary = config.get_summary()

print('ðŸ“‹ Hardware Configuration:')
for key, value in summary.items():
    print(f'  {key}: {value}')

# Set environment variables for optimization
env_vars = config.get_environment_variables()
for key, value in env_vars.items():
    os.environ[key] = value
    print(f'ðŸ”§ Set {key}={value}')

# Validate configuration
is_valid, message = config.validate_configuration()
if is_valid:
    print(f'âœ… {message}')
else:
    print(f'âš ï¸  {message}')
"

# Start the application
if [ "$BUILD_ENV" = "development" ]; then
    echo "ðŸ”§ Starting in development mode with reload..."
    exec uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload
else
    echo "ðŸš€ Starting in production mode..."
    exec uvicorn app.main:app --host 0.0.0.0 --port 8080 --workers 1
fi
EOF

RUN chmod +x /app/entrypoint.sh

# Default command
CMD ["/app/entrypoint.sh"]