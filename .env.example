# OpenTranscribe Environment Configuration
#
# SECURITY NOTICE: This is a template file with placeholder values.
# DO NOT use these placeholder values in production!
#
# For new installations:
# - Linux/Mac: ./setup-opentranscribe.sh will auto-generate secure passwords
# - Windows: The installer will auto-generate secure passwords
# - Manual: Copy this file to .env and replace ALL placeholder values
#
# All secrets are auto-generated during installation for maximum security.
# You can customize values in .env after installation if needed.

#=============================================================================
# DATABASE CONFIGURATION
#=============================================================================

# PostgreSQL Database Settings
POSTGRES_HOST=postgres
POSTGRES_PORT=5176
POSTGRES_USER=postgres
# CRITICAL: Auto-generated during install (32-char random hex)
POSTGRES_PASSWORD=CHANGE_ME_auto_generated_on_install
POSTGRES_DB=opentranscribe

# Database Initialization SQL Path
# Development: ./database/init_db.sql (relative to repo root)
# Production/Offline: ./init_db.sql (relative to installation directory)
# This is automatically set by installation scripts
INIT_DB_PATH=./database/init_db.sql

#=============================================================================
# OBJECT STORAGE (MinIO S3-Compatible)
#=============================================================================

# MinIO Storage Settings
MINIO_HOST=minio
MINIO_PORT=5178
MINIO_CONSOLE_PORT=5179
# CRITICAL: Auto-generated during install (32-char random hex)
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=CHANGE_ME_auto_generated_on_install
MEDIA_BUCKET_NAME=opentranscribe

#=============================================================================
# REDIS CACHE & MESSAGE BROKER
#=============================================================================

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=5177
# OPTIONAL: Set a password for Redis (recommended for production)
# Auto-generated during install (32-char random hex)
# Leave empty to disable Redis authentication (not recommended for production)
REDIS_PASSWORD=CHANGE_ME_auto_generated_on_install

#=============================================================================
# SEARCH ENGINE (OpenSearch)
#=============================================================================

# OpenSearch Configuration
OPENSEARCH_HOST=opensearch
OPENSEARCH_PORT=5180
OPENSEARCH_ADMIN_PORT=5181
# OPTIONAL: OpenSearch credentials (currently security plugin is disabled)
# Enable for production by setting DISABLE_SECURITY_PLUGIN=false in docker-compose
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=CHANGE_ME_auto_generated_on_install

#=============================================================================
# SECURITY & AUTHENTICATION
#=============================================================================

# JWT Token Configuration
# CRITICAL: Used for user session authentication
# Auto-generated during install (64-char random hex for maximum security)
JWT_SECRET_KEY=CHANGE_ME_auto_generated_on_install
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440

# API Key Encryption
# CRITICAL: Used to encrypt LLM API keys stored in database
# Auto-generated during install (64-char random hex)
# NEVER change this after first use or encrypted data will be lost!
ENCRYPTION_KEY=CHANGE_ME_auto_generated_on_install

#=============================================================================
# APPLICATION PORTS (External Access)
#=============================================================================

# External port configuration (accessible from host machine)
# Consistent ports across all environments to avoid confusion
FRONTEND_PORT=5173          # Web UI
BACKEND_PORT=5174           # API Server
FLOWER_PORT=5175            # Celery Task Monitor
POSTGRES_PORT=5176          # Database (for admin tools)
REDIS_PORT=5177             # Redis (for debugging)
MINIO_PORT=5178             # MinIO API
MINIO_CONSOLE_PORT=5179     # MinIO Web Console
OPENSEARCH_PORT=5180        # OpenSearch API
OPENSEARCH_ADMIN_PORT=5181  # OpenSearch Admin

#=============================================================================
# AI MODEL STORAGE & CACHING
#=============================================================================

# Model Cache Directory (on host machine)
# This directory persists AI models between container restarts (~2-6GB total)
MODEL_CACHE_DIR=./models

# Container Internal Paths (do not change unless you know what you're doing)
MODEL_BASE_DIR=/app/models
MODELS_DIRECTORY=/app/models
TEMP_DIR=/app/temp

#=============================================================================
# HARDWARE DETECTION & GPU CONFIGURATION
#=============================================================================

# Hardware Configuration (auto-detected by setup scripts)
# Options: auto, cuda, mps, cpu
TORCH_DEVICE=auto

# Compute Type (auto-detected based on GPU capabilities)
# Options: auto, float16, float32, int8
COMPUTE_TYPE=auto

# GPU Usage (auto-detected)
# Options: auto, true, false
USE_GPU=auto

# GPU Device Selection (for multi-GPU systems)
# Selects which GPU to use (0 = first GPU, 1 = second GPU, etc.)
GPU_DEVICE_ID=0

# Batch Size (auto-detected based on available GPU memory)
# Options: auto, or specific number (1, 8, 16, 32)
BATCH_SIZE=auto

#=============================================================================
# AI MODELS CONFIGURATION
#=============================================================================

# Whisper Speech Recognition Model
# Options: tiny, base, small, medium, large-v1, large-v2, large-v3
# Larger models = better accuracy but slower and more VRAM
# Recommended: large-v2 for GPU, small for CPU
WHISPER_MODEL=large-v2

# Speaker Diarization Model
DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
MIN_SPEAKERS=1
MAX_SPEAKERS=10

# HuggingFace Token (REQUIRED for speaker diarization)
# Get your token at: https://huggingface.co/settings/tokens
# You must accept PyAnnote model terms at: https://huggingface.co/pyannote/speaker-diarization-3.1
HUGGINGFACE_TOKEN=

#=============================================================================
# LLM PROVIDER CONFIGURATION (Optional - for AI Summarization)
#=============================================================================

# LLM Provider Selection
# IMPORTANT: Users configure LLM providers through the Web UI (Settings → LLM Provider)
# This is a system-wide default fallback when no user settings exist
#
# Options: vllm, openai, ollama, anthropic, openrouter, or leave empty
# Leave empty for transcription-only mode (no AI summarization/speaker identification)
LLM_PROVIDER=

# ─────────────────────────────────────────────────────────────────────────
# vLLM (Self-Hosted Open Source LLM Server)
# ─────────────────────────────────────────────────────────────────────────
VLLM_BASE_URL=http://localhost:8012/v1
VLLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2
VLLM_API_KEY=

# ─────────────────────────────────────────────────────────────────────────
# OpenAI (Commercial Cloud API)
# ─────────────────────────────────────────────────────────────────────────
OPENAI_API_KEY=
OPENAI_MODEL_NAME=gpt-4o-mini
OPENAI_BASE_URL=https://api.openai.com/v1

# ─────────────────────────────────────────────────────────────────────────
# Ollama (Self-Hosted Local LLM)
# ─────────────────────────────────────────────────────────────────────────
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=llama2:7b-chat

# ─────────────────────────────────────────────────────────────────────────
# Anthropic Claude (Commercial Cloud API)
# ─────────────────────────────────────────────────────────────────────────
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL_NAME=claude-3-haiku-20240307
ANTHROPIC_BASE_URL=https://api.anthropic.com

# ─────────────────────────────────────────────────────────────────────────
# OpenRouter (Multi-Provider API Gateway)
# ─────────────────────────────────────────────────────────────────────────
OPENROUTER_API_KEY=
OPENROUTER_MODEL_NAME=anthropic/claude-3-haiku
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

#=============================================================================
# FRONTEND CONFIGURATION
#=============================================================================

# Node Environment
NODE_ENV=production

# API Connection URLs (used by frontend to connect to backend)
VITE_API_BASE_URL=http://localhost:5174/api
VITE_WS_BASE_URL=ws://localhost:5174/ws

# Flower (Celery Task Monitor) Configuration
VITE_FLOWER_PORT=5175
VITE_FLOWER_URL_PREFIX=flower

#=============================================================================
# ADVANCED CONFIGURATION (Internal Docker Settings)
#=============================================================================
# The following variables are used internally by Docker containers
# and typically don't need to be changed unless you're doing advanced customization

# Internal service hostnames (Docker Compose service names)
# These are DNS names within the Docker network
# POSTGRES_HOST=postgres (already set above)
# MINIO_HOST=minio (already set above)
# REDIS_HOST=redis (already set above)
# OPENSEARCH_HOST=opensearch (already set above)

# Celery Configuration (auto-configured from REDIS settings)
# CELERY_BROKER_URL is automatically constructed from REDIS_HOST, REDIS_PORT, REDIS_PASSWORD
# CELERY_RESULT_BACKEND is automatically constructed from REDIS_HOST, REDIS_PORT, REDIS_PASSWORD

# Database URL (auto-constructed from POSTGRES_* variables)
# DATABASE_URL is automatically built by the backend from individual POSTGRES_* settings

#=============================================================================
# OFFLINE/AIR-GAPPED DEPLOYMENT
#=============================================================================
# For offline deployments, the installer will set these automatically

# HuggingFace Hub Offline Mode
# HF_HUB_OFFLINE=1

# Temporary Directory Override
# TEMP_DIR=/opt/opentranscribe/temp
