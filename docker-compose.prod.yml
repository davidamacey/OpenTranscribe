version: '3.8'

# OpenTranscribe Production Configuration
# Cross-platform compatible with automatic GPU detection

services:
  postgres:
    image: postgres:14-alpine
    restart: always
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-opentranscribe}
    ports:
      - "${POSTGRES_PORT:-5176}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 5s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio
    restart: always
    volumes:
      - minio_data:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
    ports:
      - "${MINIO_PORT:-5178}:9000"
      - "${MINIO_CONSOLE_PORT:-5179}:9001"
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 10s
      retries: 5

  redis:
    image: redis:7-alpine
    restart: always
    ports:
      - "${REDIS_PORT:-5177}:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  opensearch:
    image: opensearchproject/opensearch:2.5.0
    restart: always
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - DISABLE_SECURITY_PLUGIN=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    ports:
      - "${OPENSEARCH_PORT:-5180}:9200"
      - "${OPENSEARCH_ADMIN_PORT:-5181}:9600"
    healthcheck:
      test: ["CMD-SHELL", "curl -sS http://localhost:9200 || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 20

  db-init:
    image: postgres:14-alpine
    restart: "no"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./init_db.sql:/init_db.sql:ro
    environment:
      - PGPASSWORD=${POSTGRES_PASSWORD:-postgres}
    command: >
      sh -c "
        echo 'ðŸ—„ï¸  Initializing database schema...' &&
        psql -h postgres -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-opentranscribe} -f /init_db.sql &&
        echo 'âœ… Database schema initialized!'
      "

  backend:
    image: davidamacey/opentranscribe-backend:latest
    restart: always
    volumes:
      - backend_models:/app/models
      - backend_temp:/app/temp
    ports:
      - "${BACKEND_PORT:-5174}:8080"
    environment:
      # Database
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-opentranscribe}
      # Storage
      - MINIO_HOST=${MINIO_HOST:-minio}
      - MINIO_PORT=9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MEDIA_BUCKET_NAME=${MEDIA_BUCKET_NAME:-opentranscribe}
      # Cache
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=6379
      # Search
      - OPENSEARCH_HOST=${OPENSEARCH_HOST:-opensearch}
      - OPENSEARCH_PORT=9200
      # Security
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-change_this_in_production}
      - JWT_ALGORITHM=${JWT_ALGORITHM:-HS256}
      - JWT_ACCESS_TOKEN_EXPIRE_MINUTES=${JWT_ACCESS_TOKEN_EXPIRE_MINUTES:-60}
      # Models
      - MODEL_BASE_DIR=${MODEL_BASE_DIR:-/app/models}
      - TEMP_DIR=${TEMP_DIR:-/app/temp}
      # Hardware (auto-detected)
      - TORCH_DEVICE=${TORCH_DEVICE:-auto}
      - COMPUTE_TYPE=${COMPUTE_TYPE:-auto}
      - USE_GPU=${USE_GPU:-auto}
      - GPU_DEVICE_ID=${GPU_DEVICE_ID:-0}
      # AI Models
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v2}
      - BATCH_SIZE=${BATCH_SIZE:-auto}
      - DIARIZATION_MODEL=${DIARIZATION_MODEL:-pyannote/speaker-diarization-3.1}
      - MIN_SPEAKERS=${MIN_SPEAKERS:-1}
      - MAX_SPEAKERS=${MAX_SPEAKERS:-10}
    depends_on:
      db-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      opensearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    # GPU configuration (only applied when GPU detected)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
    runtime: ${DOCKER_RUNTIME:-}

  celery-worker:
    image: davidamacey/opentranscribe-backend:latest
    restart: always
    command: celery -A app.core.celery worker --loglevel=info --concurrency=1
    volumes:
      - backend_models:/app/models
      - backend_temp:/app/temp
    environment:
      # Same environment as backend
      - POSTGRES_HOST=${POSTGRES_HOST:-postgres}
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-opentranscribe}
      - MINIO_HOST=${MINIO_HOST:-minio}
      - MINIO_PORT=9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minioadmin}
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=6379
      - OPENSEARCH_HOST=${OPENSEARCH_HOST:-opensearch}
      - OPENSEARCH_PORT=9200
      - MODEL_BASE_DIR=${MODEL_BASE_DIR:-/app/models}
      - TEMP_DIR=${TEMP_DIR:-/app/temp}
      - TORCH_DEVICE=${TORCH_DEVICE:-auto}
      - COMPUTE_TYPE=${COMPUTE_TYPE:-auto}
      - USE_GPU=${USE_GPU:-auto}
      - GPU_DEVICE_ID=${GPU_DEVICE_ID:-0}
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
      - WHISPER_MODEL=${WHISPER_MODEL:-large-v2}
      - BATCH_SIZE=${BATCH_SIZE:-auto}
      - DIARIZATION_MODEL=${DIARIZATION_MODEL:-pyannote/speaker-diarization-3.1}
      - MIN_SPEAKERS=${MIN_SPEAKERS:-1}
      - MAX_SPEAKERS=${MAX_SPEAKERS:-10}
    depends_on:
      - postgres
      - redis
      - minio
      - opensearch
    # GPU configuration (only applied when GPU detected)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${GPU_DEVICE_ID:-0}']
              capabilities: [gpu]
    runtime: ${DOCKER_RUNTIME:-}

  frontend:
    image: davidamacey/opentranscribe-frontend:latest
    restart: always
    ports:
      - "${FRONTEND_PORT:-5173}:80"
    environment:
      - NODE_ENV=production
      - VITE_API_BASE_URL=http://localhost:${BACKEND_PORT:-5174}/api
      - VITE_WS_BASE_URL=ws://localhost:${BACKEND_PORT:-5174}/ws
      - VITE_FLOWER_PORT=${FLOWER_PORT:-5175}
      - VITE_FLOWER_URL_PREFIX=${VITE_FLOWER_URL_PREFIX:-flower}
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:80"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  flower:
    image: davidamacey/opentranscribe-backend:latest
    restart: always
    command: >
      python -m celery -A app.core.celery flower
      --port=5555
      --url_prefix=${VITE_FLOWER_URL_PREFIX:-flower}
      --persistent=True
      --db=/app/flower.db
      --broker=redis://${REDIS_HOST:-redis}:6379/0
    ports:
      - "${FLOWER_PORT:-5175}:5555"
    depends_on:
      - redis
      - celery-worker
    environment:
      - CELERY_BROKER_URL=redis://${REDIS_HOST:-redis}:6379/0
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
    volumes:
      - flower_data:/app

volumes:
  postgres_data:
  minio_data:
  redis_data:
  opensearch_data:
  backend_models:
  backend_temp:
  flower_data:

networks:
  default:
    driver: bridge