# OpenTranscribe Configuration
# This file works for both development and production

# Database Configuration
POSTGRES_HOST=postgres
POSTGRES_PORT=5176
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres  # Change this in production!
POSTGRES_DB=opentranscribe

# MinIO Object Storage Configuration
MINIO_HOST=minio
MINIO_PORT=5178
MINIO_CONSOLE_PORT=5179
MINIO_ROOT_USER=minioadmin     # Change this in production!
MINIO_ROOT_PASSWORD=minioadmin # Change this in production!
MEDIA_BUCKET_NAME=opentranscribe

# Redis Configuration
REDIS_HOST=redis
REDIS_PORT=5177

# OpenSearch Configuration
OPENSEARCH_HOST=opensearch
OPENSEARCH_PORT=5180
OPENSEARCH_ADMIN_PORT=5181

# JWT Authentication
JWT_SECRET_KEY=change_this_in_production  # MUST change this in production!
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440

# Encryption Key for API Key Storage
# MUST change this in production for secure API key encryption!
ENCRYPTION_KEY=change_this_in_production_for_api_key_encryption

# Model Storage
MODEL_BASE_DIR=/app/models
TEMP_DIR=/app/temp
MODEL_CACHE_DIR=./models         # Directory to store downloaded AI models

# Hardware Detection (auto-detected by setup script)
TORCH_DEVICE=auto  # Options: auto, cuda, mps, cpu
COMPUTE_TYPE=auto  # Options: auto, float16, float32, int8
USE_GPU=auto       # Will be auto-detected
GPU_DEVICE_ID=0

# AI Models Configuration
WHISPER_MODEL=large-v2  # Options: tiny, base, small, medium, large-v1, large-v2
BATCH_SIZE=auto         # Will be auto-detected based on hardware
DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
MIN_SPEAKERS=1
MAX_SPEAKERS=10

# Note: LLM model configuration is now handled through user-specific settings in the database.
# The LLM_PROVIDER and related settings below are system-wide defaults used as fallbacks.

# HuggingFace Token (REQUIRED for speaker diarization)
# Get your token at: https://huggingface.co/settings/tokens
HUGGINGFACE_TOKEN=your_huggingface_token_here

# LLM Configuration for AI Summarization and Speaker Identification
# Users configure their LLM providers through: Settings â†’ LLM Provider tab in the web UI
# All settings including API keys are stored securely in the database per user
#
# Set LLM_PROVIDER for system-wide default (optional - can leave empty for transcription-only mode)
LLM_PROVIDER=

# External Port Configuration
# Uses consistent ports across all environments to avoid confusion
FRONTEND_PORT=5173
BACKEND_PORT=5174
FLOWER_PORT=5175
POSTGRES_PORT=5176
REDIS_PORT=5177
MINIO_PORT=5178
MINIO_CONSOLE_PORT=5179
OPENSEARCH_PORT=5180
OPENSEARCH_ADMIN_PORT=5181

# Frontend Configuration
NODE_ENV=production
VITE_FLOWER_URL_PREFIX=flower

# API URLs for Frontend
VITE_API_BASE_URL=http://localhost:5174/api
VITE_WS_BASE_URL=ws://localhost:5174/ws
VITE_FLOWER_PORT=5175