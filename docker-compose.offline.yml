# OpenTranscribe Offline/Airgapped Deployment Overrides
# Use with: docker compose -f docker-compose.yml -f docker-compose.offline.yml up
#
# This file contains ONLY offline deployment-specific settings:
#   - Never pull images (use pre-loaded images)
#   - Offline mode for HuggingFace
#   - Offline-specific volume paths

services:
  postgres:
    pull_policy: never

  minio:
    pull_policy: never

  redis:
    pull_policy: never

  opensearch:
    pull_policy: never

  backend:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    # No volumes needed - temp files live in container only

  celery-worker:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    volumes:
      # Offline: Use absolute paths for airgapped systems
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/torch:/home/appuser/.cache/torch
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/nltk_data:/home/appuser/.cache/nltk_data
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/sentence-transformers:/home/appuser/.cache/sentence-transformers
      # No temp volume needed - temp files live in container only
    environment:
      # Offline mode for HuggingFace (prevents network calls)
      - HF_HUB_OFFLINE=1

  celery-download-worker:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    volumes:
      # Offline: Use absolute paths for airgapped systems
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/torch:/home/appuser/.cache/torch
    environment:
      # Offline mode for HuggingFace (prevents network calls)
      - HF_HUB_OFFLINE=1

  celery-cpu-worker:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    # No volumes needed for CPU worker
    environment:
      # Offline mode for HuggingFace (prevents network calls)
      - HF_HUB_OFFLINE=1

  celery-nlp-worker:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    # No volumes needed for NLP worker
    environment:
      # Offline mode for HuggingFace (prevents network calls)
      - HF_HUB_OFFLINE=1

  celery-beat:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    # No volumes needed - scheduler state lives in container only

  frontend:
    image: davidamacey/opentranscribe-frontend:latest
    pull_policy: never
    ports:
      - "${FRONTEND_PORT:-5173}:8080"  # Production NGINX port
    environment:
      - NODE_ENV=production
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  flower:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never
    ports:
      - "${FLOWER_PORT:-5175}:5555"  # Flower web UI

  # GPU Scaled Worker - Offline overrides
  # NOTE: No 'scale' parameter here - base has scale: 0, gpu-scale.yml sets scale: 1
  # This overlay only provides offline-specific settings (image, pull_policy, paths)
  celery-worker-gpu-scaled:
    image: davidamacey/opentranscribe-backend:latest
    pull_policy: never  # Use pre-loaded images (no network access)
    volumes:
      # Offline: Use absolute paths for airgapped systems
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/huggingface:/home/appuser/.cache/huggingface
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/torch:/home/appuser/.cache/torch
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/nltk_data:/home/appuser/.cache/nltk_data
      - ${MODEL_CACHE_DIR:-/opt/opentranscribe/models}/sentence-transformers:/home/appuser/.cache/sentence-transformers
    environment:
      # Offline mode for HuggingFace (prevents network calls)
      - HF_HUB_OFFLINE=1
