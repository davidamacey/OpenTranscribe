# docker-compose.gpu-scale.yml
# Optional overlay for multi-GPU worker scaling
#
# This overlay enables parallel GPU workers on a dedicated GPU device,
# significantly increasing transcription throughput for users with multiple GPUs.
#
# Usage:
#   ./opentr.sh start dev --gpu-scale
#   OR
#   docker compose -f docker-compose.yml -f docker-compose.override.yml -f docker-compose.gpu-scale.yml up
#
# Note: This overlay extends the base celery-worker-gpu-scaled definition from docker-compose.yml
# and adds GPU-specific configuration. Image/build/volumes come from environment overlays
# (override.yml for dev, prod.yml for production, offline.yml for airgapped).
#
# Configuration:
#   Set these variables in your .env file:
#   - GPU_SCALE_DEVICE_ID=2           # GPU device ID to use (default: 2)
#   - GPU_SCALE_WORKERS=4             # Number of parallel workers (default: 4)
#
# Example Hardware Setup:
#   GPU 0: NVIDIA RTX A6000 (49GB)    - Running LLM model
#   GPU 1: RTX 3080 Ti (12GB)         - Default single worker (disabled when scaling enabled)
#   GPU 2: NVIDIA RTX A6000 (49GB)    - Scaled workers (4 parallel in single container)

services:
  # Disable the default single GPU worker when scaling is enabled
  celery-worker:
    scale: 0

  # Scaled GPU Worker - GPU-specific settings
  # Base definition (env, tmpfs, depends_on) in docker-compose.yml
  # Image/build/volumes from override.yml (dev) or prod.yml/offline.yml
  celery-worker-gpu-scaled:
    scale: 1  # Enable this service (base has scale: 0)
    command: >
      celery -A app.core.celery worker
      -Q gpu
      --concurrency=${GPU_SCALE_WORKERS:-4}
      --prefetch-multiplier=${GPU_SCALE_WORKERS:-4}
      --max-tasks-per-child=10
      -n gpu-scaled@%h
      --loglevel=info
    environment:
      # GPU-specific environment variable (extends base environment)
      - CUDA_VISIBLE_DEVICES=${GPU_SCALE_DEVICE_ID:-2}
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.core.celery inspect ping -d gpu-scaled@$$HOSTNAME"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # GPU configuration for multi-GPU scaling
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["${GPU_SCALE_DEVICE_ID:-2}"]
              capabilities: [gpu]
